input {

#  file { # AL coger los archivos directamente, nos ahorraríamos usar FileBeat
#      path => "/usr/share/logstash/logs/*.log" #Path de donde cogerá los logs
#      exclude => "*.json" #Excluir archivos que seguirán el patrón siguiente
#      start_position => "beginning" #Comenzará a leer desde el principio, también podemos poner 'end'
#      sincedb_path => "/usr/share/logstash/sincedb/punuteros.sincedb" # Puntero para guardar la posicion donde se ha quedado
#      codec => multiline { #Habrá más de una linea para un evento (java.lang.error)
#        pattern => "^www.*" #Empeza por www. y continuar por lo que sea
#        negate => "true" #Los que no coincidan con el patron
#        what => "previous" #Los que no encajen lo asignarán al evento anterior 
#      }
#   Podríamos tener varios Pipelines con diferentes puertos escuchado
#   de manera que tendríamos varios Beats enviando información diferente
#   y siendo recogidos por cada logstash
  
  beats { # Entrada por Beats
    port => 5044 # El puerto por el que enviará los datos filebeat
    host => logstash_host #Host de Logstash
  }
  
#  file {
#    path => "/usr/share/logstash/logs/mi-log.log"
#    start_position => "beginning"
#  }
  
#  stdin {} #Introducir por teclado

}

filter {
    grok {
          patterns_dir => "patterns"
          match => {"message" => [
              '%{IPV4:ip} - - \[%{HTTPDATE:date}\] \"%{GREEDYDATA:action}\" %{NUMBER:status} %{NUMBER:id_user} \"%{DATA:url}\" \"%{DATA:browser}\"',  
              "%{COMMON_LOG}",
              "%{COMPLETO}",
              "%{ALTERNATIVA_SIN_ID}",
              "%{ALTERNATIVA_SIN_ID_URL}",
              "%{ALTERNATIVA_SIN_URL}",
              "%{ALTERNATIVA_SIN_URL_BROWSER}"
          ]}
    }
      date {
        match => ["date" , "dd/MMM/yyyy:HH:mm:ss Z"]
        target => "@timestamp"
      }
      mutate {
        remove_field => ["ecs.version","@version","agent.name","agent.ephemeral_id","agent.id"]
      }
}

output {
  if "dataset" == [fields][tags] {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "dataset-%{+YYYY.MM.dd}"
        #manage_template => true
        #template_overwrite => true
        #template_name => "core"
       # template => "/usr/share/logstash/templates/core.json"
        
      }
  }
  if "core" == [fields][tags] {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "core-%{+YYYY.MM.dd}"
       # manage_template => true
        #template_overwrite => true
        #template_name => "dataset"
        #template => "/usr/share/logstash/templates/dataset.json"
        
      } 
  }
}