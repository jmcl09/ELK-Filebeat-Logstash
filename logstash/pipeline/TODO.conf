  input {
    beats { 
      port => 5044 
      host => logstash_host 
    }
      #  file { # AL coger los archivos directamente, nos ahorraríamos usar FileBeat
      #      path => "/usr/share/logstash/logs/*.log" #Path de donde cogerá los logs
      #      exclude => "*.json" #Excluir archivos que seguirán el patrón siguiente
      #      start_position => "beginning" #Comenzará a leer desde el principio, también podemos poner 'end'
      #      sincedb_path => "/usr/share/logstash/sincedb/punuteros.sincedb" # Puntero para guardar la posicion donde se ha quedado
      #      codec => multiline { #Habrá más de una linea para un evento (java.lang.error)
      #        pattern => "^www.*" #Empeza por www. y continuar por lo que sea
      #        negate => "true" #Los que no coincidan con el patron
      #        what => "previous" #Los que no encajen lo asignarán al evento anterior 
      #      }
      #   Podríamos tener varios Pipelines con diferentes puertos escuchado
      #   de manera que tendríamos varios Beats enviando información diferente
      #   y siendo recogidos por cada logstash
  }

  filter {
      if "dataset" == [fields][tags] {
          grok {
              patterns_dir => "patterns"
              match => {"message" => [
                  '%{IPV4:ip} - - \[%{HTTPDATE:date}\] \"%{GREEDYDATA:action}\" %{NUMBER:status} %{NUMBER:id_user} \"%{DATA:url}\" \"%{DATA:browser}\"',  
                  "%{COMMON_LOG}",
                  "%{COMPLETO}",
                  "%{ALTERNATIVA_SIN_ID}",
                  "%{ALTERNATIVA_SIN_ID_URL}",
                  "%{ALTERNATIVA_SIN_URL}",
                  "%{ALTERNATIVA_SIN_URL_BROWSER}"
              ]}
              }
          date {
              match => ["date" , "dd/MMM/yyyy:HH:mm:ss Z"]
              target => "@timestamp"
              }
          mutate {
              remove_field => ["ecs.version","@version","agent.name","agent.ephemeral_id","agent.id"]
              }
      }

      if "core" == [fields][tags] {
          grok {
              patterns_dir => "patterns"
              match => {"message" => 
                ["%{WORD:type}  %{DATESTAMP:fecha} %{NUMBER:pid} \[%{WORD:status}\] %{GREEDYDATA:description} %{JAVACLASS:class}\:%{NUMBER:line} %{GREEDYDATA}\{%{GREEDYDATA}\}%{WORD}\.%{WORD:action}\: %{GREEDYDATA:time_execution}"
                    ]}
          }
          mutate {
              remove_field => ["ecs.version","@version","agent.name","agent.ephemeral_id","agent.id"]
          }
      }

      if "cajamar" == [fields][tags] {
          grok {
            patterns_dir => "patterns"
            match => {"message" => [
              "%{DEBUG_PATTERN}",
              "%{TRACE_PATTERN}",
              "%{INFO_INOUT_PATTERN}",
              "%{INFO_TIME_PATTERN}"
              ]}
          }
          mutate {
            remove_field => ["@version","agent.ephemeral_id","agent.id","agent.name","agent.type","agent.version","ecs.version","log.offset"]
            coerce => {"time_of" => "TIEMPO DE"}
            rename => {"time_of" => "result"} 
          }
          date {
              match => ["date" , "dd/MM/yyyy HH:mm:ss,SSS"]
              target => "@timestamp"
          }
      }

      if "apache" == [fields][tags] {
          grok {
              match => [ "message", "%{COMBINEDAPACHELOG}" ]
          }
      }
  }
  output {
    if "dataset" == [fields][tags] {
      elasticsearch {
          hosts => "elasticsearch:9200"
          index => "dataset-%{+YYYY.MM.dd}"
          manage_template => true
          template_overwrite => true
          template_name => "core"
          template => "/usr/share/logstash/templates/core.json"
          
        }
    }
    if "core" == [fields][tags] {
      elasticsearch {
          hosts => "elasticsearch:9200"
          index => "core-%{+YYYY.MM.dd}"
          manage_template => true
          template_overwrite => true
          template_name => "dataset"
          template => "/usr/share/logstash/templates/dataset.json"
          
        }

        stdout {
          codec => "json_lines"
        } 
    }
    
    if "apache" == [fields][tags] {
      elasticsearch {
          hosts => "elasticsearch:9200"
          index => "apache-%{+YYYY.MM.dd}"
        # manage_template => true
          #template_overwrite => true
          #template_name => "dataset"
          #template => "/usr/share/logstash/templates/dataset.json"
          
        } 
    }

    if "cajamar" == [fields][tags] {
      if "_grokparsefailure" in [tags] {
        stdout {}
      }else{
        elasticsearch {
            hosts => "elasticsearch:9200"
            index => "cajamar-%{+YYYY.MM.dd}"
            template_name => "cajamar"
           template => "/usr/share/logstash/templates/cajamar.json"
          }
      }
      }
    }