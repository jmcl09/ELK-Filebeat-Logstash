input {

#  file { # AL coger los archivos directamente, nos ahorraríamos usar FileBeat
#      path => "/usr/share/logstash/logs/*.log" #Path de donde cogerá los logs
#      exclude => "*.json" #Excluir archivos que seguirán el patrón siguiente
#      start_position => "beginning" #Comenzará a leer desde el principio, también podemos poner 'end'
#      sincedb_path => "/usr/share/logstash/sincedb/punuteros.sincedb" # Puntero para guardar la posicion donde se ha quedado
#      codec => multiline { #Habrá más de una linea para un evento (java.lang.error)
#        pattern => "^www.*" #Empeza por www. y continuar por lo que sea
#        negate => "true" #Los que no coincidan con el patron
#        what => "previous" #Los que no encajen lo asignarán al evento anterior 
#      }
#   Podríamos tener varios Pipelines con diferentes puertos escuchado
#   de manera que tendríamos varios Beats enviando información diferente
#   y siendo recogidos por cada logstash
  
  beats { # Entrada por Beats
    port => 5044 # El puerto por el que enviará los datos filebeat
    host => logstash_host #Host de Logstash
  }
  
#  file {
#    path => "/usr/share/logstash/logs/mi-log.log"
#    start_position => "beginning"
#  }
  
#  stdin {} #Introducir por teclado

}

output {
  if "dataset" == [fields][tags] {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "dataset-%{+YYYY.MM.dd}"
        #manage_template => true
        #template_overwrite => true
        #template_name => "core"
       # template => "/usr/share/logstash/templates/core.json"
        
      }
  }
  if "core" == [fields][tags] {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "core-%{+YYYY.MM.dd}"
       # manage_template => true
        #template_overwrite => true
        #template_name => "dataset"
        #template => "/usr/share/logstash/templates/dataset.json"
        
      } 
  }
   if "apache" == [fields][tags] {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "apache-%{+YYYY.MM.dd}"
       # manage_template => true
        #template_overwrite => true
        #template_name => "dataset"
        #template => "/usr/share/logstash/templates/dataset.json"
        
      } 
  }
}

output {
  if "dataset" == [fields][tags] {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "dataset-%{+YYYY.MM.dd}"
        manage_template => true
        template_overwrite => true
        template_name => "core"
        template => "/usr/share/logstash/templates/core.json"
        
      }
  }
  if "core" == [fields][tags] {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "core-%{+YYYY.MM.dd}"
       # manage_template => true
        #template_overwrite => true
        #template_name => "dataset"
        #template => "/usr/share/logstash/templates/dataset.json"
        
      } 
  }
   if "apache" == [fields][tags] {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "apache-%{+YYYY.MM.dd}"
       # manage_template => true
        #template_overwrite => true
        #template_name => "dataset"
        #template => "/usr/share/logstash/templates/dataset.json"
        
      } 
  }

  if "cajamar" == [fields][tags] {
    if "_grokparsefailure" in [tags] {
      stdout {}
    }else{
      elasticsearch {
          hosts => "elasticsearch:9200"
          index => "cajamar-%{+YYYY.MM.dd}"
      #    template_name => "cajamar"
       #   template => "/usr/share/logstash/templates/cajamar.json"
        }
    }
    }
  }